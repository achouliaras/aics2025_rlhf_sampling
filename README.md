# aics2025_rlhf_sampling
Code for AICS2025 paper:  Maximizing the efficiency of human feedback in AI alignment: a comparative analysis
